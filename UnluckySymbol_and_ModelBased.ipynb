{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pystan\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import njit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rewards import Rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rs = Rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "805"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from Sam Zorowitz code — add citation here!\n",
    "\n",
    "@njit\n",
    "def inv_logit(arr):\n",
    "    \"\"\"Fast inverse logistic function.\"\"\"\n",
    "    return 1. / (1. + np.exp(-arr))\n",
    "\n",
    "@njit\n",
    "def softmax(arr):\n",
    "    \"\"\"Scale-robust softmax function\"\"\"\n",
    "    arr = np.exp(arr - np.max(arr))\n",
    "    return arr / arr.sum()\n",
    "\n",
    "@njit\n",
    "def phi_approx(arr):\n",
    "    '''Elementwise fast approximation of the cumulative unit normal.'''\n",
    "    return inv_logit(0.07056 * arr ** 3 + 1.5976 * arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "SA = 0\n",
    "SB = 1\n",
    "SC = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnluckySymbol(object):\n",
    "    def __init__(self, trials, Rs, a, b, eta):\n",
    "        \n",
    "        self.n_trials = trials\n",
    "        \n",
    "        self.R = Rs\n",
    "        self.state = SA\n",
    "        \n",
    "        # define parameters\n",
    "        self.alpha = a\n",
    "        self.beta = b\n",
    "        self.eta = eta\n",
    "        \n",
    "        # define values\n",
    "        self.MB = np.zeros((2, 2))\n",
    "        \n",
    "        self.rewards = np.zeros(trials)\n",
    "        self.choices = np.zeros((trials, 2))\n",
    "        self.choice1_outcomes = np.zeros(trials)\n",
    "        self.switch = np.zeros(trials)\n",
    "        self.common = np.zeros(trials)\n",
    "        \n",
    "        self.transitions = np.array([\n",
    "            [0.7, 0.3],\n",
    "            [0.3, 0.7]\n",
    "        ])\n",
    "        \n",
    "        self.transition_count = np.zeros((2,2,2))\n",
    "        self.final_state = np.zeros(trials) # 1 = SB, 2 = SC\n",
    "        \n",
    "    def possible_switch(self, choice):\n",
    "        if random.random() < 0.7:\n",
    "            return choice\n",
    "        return 1 - choice\n",
    "    \n",
    "    def update_stay_prob(self, action, t):\n",
    "        self.transition_count[\n",
    "            int(not self.rewards[t-1]),\n",
    "            int(not self.common[t-1]),\n",
    "            int(not (self.choice1_outcomes[t-1] == action))\n",
    "        ] += 1\n",
    "        \n",
    "    def compute_stay_prob(self, transition_count):\n",
    "        # stay_prob[r,c,a] = P[r,c,a] / (P[r,c,a] + P[r,c,~a]) \n",
    "        action_count = transition_count.sum(axis=-1)\n",
    "        return transition_count / action_count[:, :, np.newaxis]\n",
    "\n",
    "    def train(self, R):\n",
    "        \n",
    "        for t in range(self.n_trials):\n",
    "            \n",
    "            self.state = SA\n",
    "            \n",
    "            ## Action selection.\n",
    "            d1 = 0.7*max(self.MB[1]) + 0.3*max(self.MB[0]) - self.eta*(0.3*max(self.MB[1]) + 0.7*max(self.MB[0]))\n",
    "            \n",
    "            # choice probabilities and making choice\n",
    "            theta1 = inv_logit( self.beta * d1 )\n",
    "            choice1 = np.random.binomial(1, theta1)\n",
    "            self.choices[t,0] = choice1\n",
    "            \n",
    "            # observe outcome and possible switch\n",
    "            outcome1 = self.possible_switch(choice1)\n",
    "            self.choice1_outcomes[t] = outcome1\n",
    "            \n",
    "            # update values for stay_probs\n",
    "            if t > 0:    \n",
    "                self.update_stay_prob(outcome1, t)\n",
    "            \n",
    "            reward_probs = None\n",
    "            # update state\n",
    "            if self.choice1_outcomes[t] == 0: # went LEFT\n",
    "                self.state = SB\n",
    "                self.final_state[t] = 1\n",
    "                reward_probs = self.R[t][0:2]\n",
    "            else: # went RIGHT\n",
    "                self.state = SC\n",
    "                self.final_state[t] = 2\n",
    "                reward_probs = self.R[t][2:4]\n",
    "            \n",
    "            # count possible switch\n",
    "            if (self.choices[t,0] == 1 & self.state == SB) | (self.choices[t,0] == 0 & self.state == SC):\n",
    "                self.switch[t] = 1\n",
    "            else:\n",
    "                self.common[t] = 1\n",
    "            \n",
    "            # possible value reduction\n",
    "            value_reduc = eta if (choice1 == 0) else 1\n",
    "            \n",
    "            # make second-level choice\n",
    "            d2 = value_reduc*self.beta*(self.MB[outcome1,1] - self.MB[outcome1,0])\n",
    "\n",
    "            theta2 = inv_logit( d2 )\n",
    "            choice2 = np.random.binomial(1, theta2)\n",
    "            self.choices[t,1] = choice2\n",
    "            \n",
    "            # get what the reward is\n",
    "            final_prob = reward_probs[choice2]\n",
    "            reward = np.random.binomial(1, final_prob)\n",
    "            self.rewards[t] = reward\n",
    "            \n",
    "            # update values\n",
    "            self.MB[outcome1, choice2] = (1 - self.alpha)*self.MB[outcome1, choice2] + self.alpha*self.rewards[t]\n",
    "\n",
    "            \n",
    "    def plot(self, transition_count=None, title=\"Unlucky Symbol: Two-Step Task\", y_lim=0.5):\n",
    "        _,ax = plt.subplots(1,1,figsize=[10,6])\n",
    "\n",
    "        ax.set_ylim([y_lim, 1.0])\n",
    "        ax.set_ylabel('Stay Probability')\n",
    "        ax.set_title(title)\n",
    "\n",
    "        if transition_count is None:\n",
    "            transition_count = self.transition_count\n",
    "        \n",
    "        stay_probs = self.compute_stay_prob(transition_count)\n",
    "        \n",
    "        common = [stay_probs[0,0,0], stay_probs[1,0,0]]\n",
    "        uncommon = [stay_probs[0,1,0], stay_probs[1,1,0]]\n",
    "        \n",
    "        ax.set_xticks([1.5,3.5])\n",
    "        ax.set_xticklabels(['Rewarded', 'Unrewarded'])\n",
    "        ax.set_ylim(0,1)\n",
    "        \n",
    "        c = plt.bar([1,3], common, color='b', width=0.5)\n",
    "        uc = plt.bar([2,4], uncommon, color='r', width=0.5)\n",
    "        ax.legend( (c[0], uc[0]), ('Common', 'Uncommon') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_agents = 1\n",
    "trials = 400\n",
    "alpha = 0.5\n",
    "beta = 5.00\n",
    "eta  = 0.5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agents = UnluckySymbol(trials, Rs, alpha, beta, eta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(47404)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = agents.train(Rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agents.final_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rew = agents.rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rares = agents.switch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "commons = agents.common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# looking for HIGHER STAY PROBABILITY:\n",
    "    # if common and was rewarded ()\n",
    "    # or uncommon and wasn't rewarded (switch, and no reward)\n",
    "\n",
    "com_rew = []\n",
    "com_unrew = []\n",
    "\n",
    "rare_unrew = []\n",
    "rare_rew = []\n",
    "    \n",
    "for i in range(trials):\n",
    "    if (commons[i] == 1):\n",
    "        com_rew.append(i) if (rew[i] == 1) else com_unrew.append(i)\n",
    "\n",
    "    if (rares[i] == 1):\n",
    "        rare_unrew.append(i) if (rew[i] == 0) else rare_rew.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(com_rew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(rare_unrew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(rare_rew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(com_unrew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agents.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [EDIT] Sam Notes\n",
    "\n",
    "In this cell, I'll review the equations for the model-based agent, originally defined in the [supplement of Daw et al (2011)](https://ars.els-cdn.com/content/image/1-s2.0-S0896627311001255-mmc1.pdf). \n",
    "\n",
    "#### Stage 2 Choice\n",
    "\n",
    "In stage 2, the agent makes a choice between two actions, $Q(s_i, a_1)$ and $Q(s_i,a_2$), conditioned on the current state. As discussed in [Daw (2011)](https://pdfs.semanticscholar.org/43c3/d7653710bbb477df108fc2ed2729429d053c.pdf), in the case of two options, the softmax reduces to the [inverse logit function](https://en.wikipedia.org/wiki/Logistic_function). Thus, the probability of the agent taking action 1 is:\n",
    "\n",
    "$$ p( a_1 \\mid s_i, \\beta_2 ) = \\text{logit}^{-1} \\left( \\beta_2 \\cdot [Q(s_i, a_1) - Q(s_i, a_2)] \\right) = \\frac{1}{1 + \\exp \\left(-\\beta_2 \\cdot [Q(s_i, a_1) - Q(s_i, a_2)] \\right)} $$\n",
    "\n",
    "Note that the action probability is a function of a choice sensitivity (inverse temperature) parameter, $\\beta_2$. The subscript indicates that this parameter is specific to the second stage. As you will see below, we introduce a separate choice sensitivity parameter for first stage choice (even though we typically set these to the same value).\n",
    "\n",
    "#### Stage 2 Learning\n",
    "\n",
    "In stage 2, following a choice, the agent updates its expectations of the value of the chosen action, $Q(s_{i,t+1} a_{i,t+1})$, based on the observed reward, $r_t$. This update folows temporal difference learning:\n",
    "\n",
    "$$ Q(s_{i,t+1} a_{i,t+1}) = Q(s_{i,t}, a_{i,t}) + \\eta_2 \\delta_t $$\n",
    "\n",
    "where $\\delta_t$ is the reward prediction error on trial $t$, defined as:\n",
    "\n",
    "$$ \\delta_t = r_t - Q(s_{i,t}, a_{i,t}) $$\n",
    "\n",
    "Two notes here:\n",
    "\n",
    "1. We introduce the trial $t$ notation here to denote that learning updates affect behavior on the next trial.\n",
    "2. We introduce the stage notation here for learning rate to indicate that this parameter is specific to stage 2.\n",
    "\n",
    "#### Stage 1 Choice\n",
    "\n",
    "Now here's the complicated part. We make two assumptions about the model-based agent:\n",
    "\n",
    "1. The agent recomputes the value of each stage 1 action based on its current estimates of the value of the second stage choices at the start of each trial.\n",
    "2. The agent performs this computation assuming an *off-policy* strategy (i.e. assuming it will take the best action at any successor state).\n",
    "\n",
    "Following Bellman's equation, the model-based agent computes the value of each first stage action taking into consideration the state-transition probaiblities, $T(s' \\mid s_1, a_i)$, and value of the best action in each successor state. \n",
    "\n",
    "For notational convenience, let's define the transition probabilities as:\n",
    "- $ p( s_2 \\mid s_1, a_1) = 0.7 $, i.e. 70% probability of ending up in State 2 given Action 1 in State 1\n",
    "- $ p( s_3 \\mid s_1, a_1) = 0.3 $, i.e. 30% probability of ending up in State 3 given Action 1 in State 1\n",
    "- $ p( s_2 \\mid s_1, a_2) = 0.3 $, i.e. 30% probability of ending up in State 2 given Action 2 in State 1\n",
    "- $ p( s_3 \\mid s_1, a_2) = 0.7 $, i.e. 70% probability of ending up in State 3 given Action 2 in State 1\n",
    "\n",
    "Then we can define the value of action 1 in stage 1 as:\n",
    "\n",
    "$$ Q(s_1, a_1) = p( s_2 \\mid s_1, a_1) \\cdot \\max Q(s_2, a) + p( s_3 \\mid s_1, a_1) \\cdot \\max Q(s_3, a) $$\n",
    "$$ = 0.7 \\cdot \\max Q(s_2, a) + 0.3 \\cdot \\max Q(s_3, a) $$\n",
    "\n",
    "and the value of action 2 in stage 1 as:\n",
    "\n",
    "$$ Q(s_1, a_2) = p( s_2 \\mid s_1, a_2) \\cdot \\max Q(s_2, a) + p( s_3 \\mid s_1, a_2) \\cdot \\max Q(s_3, a) $$\n",
    "$$ = 0.3 \\cdot \\max Q(s_2, a) + 0.7 \\cdot \\max Q(s_3, a) $$\n",
    "\n",
    "And finally, we use the inverse logit function to assign probabilities of taking either action 1 vs. action 2 in stage 1:\n",
    "\n",
    "$$ p( a_1 \\mid s_1, \\beta_1 ) = \\text{logit}^{-1} \\left( \\beta_1 \\cdot [Q(s_1, a_1) - Q(s_1, a_2)] \\right) = \\frac{1}{1 + \\exp \\left(-\\beta_1 \\cdot [Q(s_1, a_1) - Q(s_1, a_2)] \\right)} $$\n",
    "\n",
    "\n",
    "Note that the action probability is a function of a separate choice sensitivity (inverse temperature) parameter, $\\beta_1$. The subscript indicates that this parameter is specific to the first stage. As noted above, we typically set the value of choice sensitivity for both stages, $\\beta_1$ and $\\beta_2$, to be the same but they don't have to be!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model-Based Strategy\n",
    "\n",
    "class model_based(object):\n",
    "    def __init__(self, trials, Rs, a, b1, b2=None):\n",
    "        \n",
    "        self.n_trials = trials\n",
    " \n",
    "        self.R = Rs\n",
    "        self.state = SA\n",
    "        \n",
    "        # define parameters\n",
    "        self.alpha = a\n",
    "        self.beta1 = b1\n",
    "        \n",
    "        if b2 == None:\n",
    "            self.beta2 = b1\n",
    "        else:\n",
    "            self.beta2 = b2\n",
    "        \n",
    "        # define values\n",
    "        self.MB = np.zeros((2, 2))\n",
    "        \n",
    "        self.rewards = np.zeros(trials)\n",
    "        self.choices = np.zeros((trials, 2))\n",
    "        self.choice1_outcomes = np.zeros(trials)\n",
    "        self.switch = np.zeros(trials)\n",
    "        self.common = np.zeros(trials)\n",
    "        \n",
    "        self.transitions = np.array([\n",
    "            [0.7, 0.3],\n",
    "            [0.3, 0.7]\n",
    "        ])\n",
    "        \n",
    "        self.transition_count = np.zeros((2,2,2))\n",
    "        self.final_state = np.zeros(trials) # 1 = SB, 2 = SC\n",
    "        \n",
    "    def possible_switch(self, choice):\n",
    "        if random.random() < 0.7:\n",
    "            return choice\n",
    "        return 1 - choice\n",
    "    \n",
    "    def update_stay_prob(self, action, t):\n",
    "        self.transition_count[\n",
    "            int(not self.rewards[t-1]),\n",
    "            int(not self.common[t-1]),\n",
    "            int(not (self.choice1_outcomes[t-1] == action))\n",
    "        ] += 1\n",
    "        \n",
    "    def compute_stay_prob(self, transition_count):\n",
    "        # stay_prob[r,c,a] = P[r,c,a] / (P[r,c,a] + P[r,c,~a]) \n",
    "        action_count = transition_count.sum(axis=-1)\n",
    "        return transition_count / action_count[:, :, np.newaxis]\n",
    "\n",
    "    def train(self, R):\n",
    "        \n",
    "        for t in range(self.n_trials):\n",
    "            \n",
    "            self.state = SA\n",
    "            \n",
    "            ## Action selection.\n",
    "            v1 = 0.7*max(self.MB[0]) + 0.3*max(self.MB[1])\n",
    "            v2 = 0.3*max(self.MB[0]) + 0.7*max(self.MB[1])\n",
    "\n",
    "            # choice probabilities and making choice\n",
    "            theta1 = inv_logit( self.beta1 * (v1 - v2) )\n",
    "            choice1 = np.random.binomial(1, theta1)\n",
    "            self.choices[t,0] = choice1\n",
    "            \n",
    "            # observe outcome and possible switch\n",
    "            outcome1 = self.possible_switch(choice1)\n",
    "            self.choice1_outcomes[t] = outcome1\n",
    "            \n",
    "            # update values for stay_probs\n",
    "            if t > 0:    \n",
    "                self.update_stay_prob(outcome1, t)\n",
    "            \n",
    "            reward_probs = None\n",
    "            # update state\n",
    "            if self.choice1_outcomes[t] == 0: # went LEFT\n",
    "                self.state = SB\n",
    "                self.final_state[t] = 1\n",
    "                reward_probs = self.R[t][0:2]\n",
    "            else: # went RIGHT\n",
    "                self.state = SC\n",
    "                self.final_state[t] = 2\n",
    "                reward_probs = self.R[t][2:4]\n",
    "            \n",
    "            # count possible switch\n",
    "            if (self.choices[t,0] == 1 & self.state == SB) | (self.choices[t,0] == 0 & self.state == SC):\n",
    "                self.switch[t] = 1\n",
    "            else:\n",
    "                self.common[t] = 1\n",
    "            \n",
    "            # make second-level choice\n",
    "            d2 = self.MB[outcome1,0] - self.MB[outcome1,1]\n",
    "\n",
    "            theta2 = inv_logit( self.beta2 * d2 )\n",
    "            choice2 = np.random.binomial(1, theta2)\n",
    "            self.choices[t,1] = choice2\n",
    "            \n",
    "            # get what the reward is\n",
    "            final_prob = reward_probs[choice2]\n",
    "            reward = np.random.binomial(1, final_prob)\n",
    "            self.rewards[t] = reward\n",
    "            \n",
    "            # update values\n",
    "            # update level 2 MB value\n",
    "            self.MB[outcome1, choice2] += self.alpha*(self.rewards[t] - self.MB[outcome1, choice2])\n",
    "            \n",
    "        return self\n",
    "            \n",
    "    def plot(self, transition_count=None, title=\"Model-Based Two-Step Task\", y_lim=0.5):\n",
    "        _,ax = plt.subplots(1,1,figsize=[10,6])\n",
    "\n",
    "        ax.set_ylim([y_lim, 1.0])\n",
    "        ax.set_ylabel('Stay Probability')\n",
    "        ax.set_title(title)\n",
    "\n",
    "        if transition_count is None:\n",
    "            transition_count = self.transition_count\n",
    "        \n",
    "        stay_probs = self.compute_stay_prob(transition_count)\n",
    "        \n",
    "        common = [stay_probs[0,0,0], stay_probs[1,0,0]]\n",
    "        uncommon = [stay_probs[0,1,0], stay_probs[1,1,0]]\n",
    "        \n",
    "        ax.set_xticks([1.5,3.5])\n",
    "        ax.set_xticklabels(['Rewarded', 'Unrewarded'])\n",
    "        ax.set_ylim(0,1)\n",
    "        \n",
    "        c = plt.bar([1,3], common, color='b', width=0.5)\n",
    "        uc = plt.bar([2,4], uncommon, color='r', width=0.5)\n",
    "        ax.legend( (c[0], uc[0]), ('Common', 'Uncommon') )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.random.seed(11408)\n",
    "\n",
    "## Define parameters\n",
    "n_agents = 1\n",
    "trials = 200\n",
    "alpha = 0.2\n",
    "beta = 10.00\n",
    "\n",
    "## Initialize agent.\n",
    "agents_MB = model_based(trials, Rs, alpha, beta)\n",
    "\n",
    "## Train agent.\n",
    "agents_MB.train(Rs[:200])\n",
    "\n",
    "agents_MB.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [EDIT] Sam Testing\n",
    "\n",
    "In this cell, I train 200 instances of `model_based` on a purely random game (i.e. all stage 2 bandits reward 50% of the time). I then try to recreate the figure from Daw et al 2011."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 136.71it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pandas import DataFrame, concat\n",
    "from tqdm import tqdm\n",
    "np.random.seed(11408)\n",
    "\n",
    "## Define parameters\n",
    "n_agents = 1\n",
    "trials = 200\n",
    "alpha = 0.2\n",
    "beta = 5\n",
    "\n",
    "Rs = np.column_stack([np.ones(trials), np.zeros(trials), np.ones(trials), np.zeros(trials)])\n",
    "Rs = np.random.binomial(1, [[0.5,0.5,0.5,0.5]], (trials,4))\n",
    "\n",
    "data = []\n",
    "for _ in tqdm(range(200)):\n",
    "    \n",
    "    ## Initialize agent.\n",
    "    agents_MB = model_based(trials, Rs[:trials], alpha, beta)\n",
    "\n",
    "    ## Train agent.\n",
    "    agents_MB.train(Rs[:trials])\n",
    "    \n",
    "    Y = agents_MB.choices[:,0].copy()\n",
    "    R = agents_MB.rewards.copy()\n",
    "    T = (Y == agents_MB.choice1_outcomes).astype(int)\n",
    "\n",
    "    prev_R = np.roll(R, 1)[1:]\n",
    "    prev_T = np.roll(T, 1)[1:]\n",
    "    stay = Y[:-1] == Y[1:]\n",
    "\n",
    "    df = DataFrame(np.column_stack([prev_R, prev_T, stay]), columns=['prev_R', 'prev_T', 'Stay'])\n",
    "    data.append(df)\n",
    "    \n",
    "## Concatenate DataFrames.\n",
    "data = concat(data)\n",
    "data.prev_R = data.prev_R.replace({1:'rewarded',0:'unrewarded'})\n",
    "data.prev_T = data.prev_T.replace({1:'common',0:'uncommon'})\n",
    "\n",
    "ax = sns.barplot('prev_R', 'Stay', 'prev_T', data=data, order=['rewarded','unrewarded'], \n",
    "                 hue_order=['common','uncommon'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [EDIT] Sam Testing\n",
    "\n",
    "In this cell, I write a second version of `ModelBased` as a comparison with the above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def inv_logit(arr):\n",
    "    \"\"\"Fast inverse logistic function.\"\"\"\n",
    "    return 1. / (1. + np.exp(-arr))\n",
    "\n",
    "\n",
    "class ModelBased(object):\n",
    "    \n",
    "    def __init__(self, beta_1, beta_2, eta_2):\n",
    "        \n",
    "        ## Define parameters.\n",
    "        self.beta_1 = beta_1\n",
    "        self.beta_2 = beta_2\n",
    "        self.eta_2 = eta_2\n",
    "        \n",
    "        ## Initialize Q-values.\n",
    "        self.Q = None\n",
    "        \n",
    "    def train(self, R, T=[[0.7,0.3],[0.3,0.7]], reset=False):\n",
    "        \n",
    "        ## Error-catching: rewards.\n",
    "        R = np.array(R)\n",
    "        \n",
    "        ## Error-catching: transition probabilities.\n",
    "        T = np.array(T)\n",
    "        \n",
    "        ## Initialize Q-values.\n",
    "        if self.Q is None or reset:\n",
    "            self.Q = 0.5 * np.ones((3,2))\n",
    "            \n",
    "        ## Preallocate space.\n",
    "        n_trials = R.shape[0]\n",
    "        Y = np.zeros((n_trials, 2), dtype=int)\n",
    "        t = np.zeros(n_trials, dtype=int)\n",
    "        r = np.zeros(n_trials)\n",
    "            \n",
    "        for i in range(n_trials):\n",
    "            \n",
    "            ## Stage 1: Re-compute Q-values.\n",
    "            self.Q[0] = T @ self.Q[1:].max(axis=1)\n",
    "            \n",
    "            ## Stage 1: Compute choice likelihood.\n",
    "            theta = inv_logit( self.beta_1 * np.diff(self.Q[0]) )\n",
    "            \n",
    "            ## Stage 1: Simulate choice.\n",
    "            Y[i,0] = np.random.binomial(1,theta)\n",
    "            \n",
    "            ## Simulate transition.\n",
    "            t[i] = np.random.binomial(1, 0.7)\n",
    "            S = np.where(t[i], Y[i,0], 1-Y[i,0]) + 1\n",
    "                        \n",
    "            ## Stage 2: Compute choice likelihood.\n",
    "            theta = inv_logit( self.beta_2 * np.diff(self.Q[S]) )\n",
    "            \n",
    "            ## Stage 2: Simulate choice.\n",
    "            Y[i,1] = np.random.binomial(1,theta)\n",
    "            \n",
    "            ## Stage 2: Observe outcome.\n",
    "            r[i] = R[i,S-1,Y[i,1]]\n",
    "            \n",
    "            ## Stage 2: Update Q-values.\n",
    "            self.Q[S,Y[i,1]] += self.eta_2 * ( r[i] - self.Q[S,Y[i,1]] )\n",
    "            \n",
    "        return Y, t, r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [EDIT] Sam Testing\n",
    "\n",
    "In this cell, I train 200 instances of `ModelBased` on a purely random game (i.e. all stage 2 bandits reward 50% of the time). I then try to recreate the figure from Daw et al 2011."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:07<00:00, 27.66it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEHCAYAAACjh0HiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAc3ElEQVR4nO3dfXhU5b3u8e9NAFMFtUqqHkGJNohoeNkE2FUrKFbxbEW3BypWrUjVqlBsu33B2kPV3V491V61alGku75uKyht96FuTvEF31AUgqKIbtgUEaJSEdSqLUjkd/6YlTiJEwiYlUlY9+e6uDLrWc+s9cuwMvesZ2Y9o4jAzMyyq0OxCzAzs+JyEJiZZZyDwMws4xwEZmYZ5yAwM8u4jsUuYHt169YtevbsWewyzMzalUWLFr0TEWWF1rW7IOjZsyfV1dXFLsPMrF2R9HpT6zw0ZGaWcQ4CM7OMcxCYmWVcu3uPwLJh8+bN1NTUsHHjxmKXslMrLS2le/fudOrUqdilWBE5CKxNqqmpoWvXrvTs2RNJxS5npxQRrF+/npqaGsrLy4tdjhWRh4asTdq4cSN77723QyBFkth777191mUOAmu7HALp82Ns4CAwM8s8v0dQBJdffjlr165l33335brrrit2OWaWcameEUgaIWmZpBWSJhVYf4Okxcm/5ZLeS7OetmLt2rW88cYbrF27ttilWJGMHz+e/v3706dPH77whS/Qv39/+vfvz8yZM4tdmmVQamcEkkqAKcDXgBpgoaRZEfFKXZ+I+F5e/+8AA9Kqx6ylfPLJJ5SUlHyubUyZMgWAVatWcdJJJ7F48eKWKM1sh6Q5NDQYWBERKwEkTQdOAV5pov8ZwI9SrKfewMvubo3dNKnrOx9QAqx+54Oi17Lo+m8Wdf9tzapVqxgxYgRDhgzhhRdeoFevXtx999306dOHcePG8dBDDzFhwgQGDRrE+PHjWbduHbvuuiu//vWv2W+//ejXrx8rV66kQ4cO/O1vf+OQQw5h5cqV/py+tWlpBsH+wJq85RpgSKGOkg4EyoG5Tay/ALgA4IADDmjZKs0aWbZsGb/5zW848sgjGTduHLfccguQu/hq3rx5AAwfPpypU6dSUVHBc889x8UXX8zcuXPp168fTzzxBMcccwx//OMfOeGEExwC7VhW3s9LMwgKfS4tmug7BpgZEZ8UWhkR04BpAFVVVU1tw6xF9OjRgyOPPBKAs846i5tuugmA008/HYAPP/yQZ555htGjR9ffZ9OmTfV9ZsyYwTHHHMP06dO5+OKLW7l6a0l17+ft7NIMghqgR95yd+DNJvqOAcanWEubsqXzbg1+WtvS+LP1dcu77Zb8v23Zwp577llwXH/kyJFceeWVbNiwgUWLFnHsscemX7DZ55Tmp4YWAhWSyiV1JvdkP6txJ0mHAF8E5qdYS5vyUcXxfHDYP/NRxfHFLsUKWL16NfPn5w7H++67j6OOOqrB+t13353y8nIeeOABIDdVw4svvghAly5dGDx4MJdccgknnXTS535T2aw1pHZGEBG1kiYAc4AS4PaIWCrpWqA6IupC4QxgekR4yMfahEMPPZS77rqLb3/721RUVHDRRRdx8803N+hz7733ctFFF/HjH/+YzZs3M2bMGPr16wfkhodGjx7N448/XoTqdx6rr60sdgnUbtgL6EjthteLWs8Bk5ekuv1ULyiLiNnA7EZtkxstX51mDWbbq0OHDkydOrVB26pVqxosl5eX86c//ang/UeNGkVzX9f07NmTl19+eYfqNGspnmLCzCzjPMWEWZ40XqGPHz+ep59+ukHbJZdcwrnnntui+zHbUQ4Cs5TVXUVs7U+30i1AbfJz5+UgMDNrwqV9MzH9md8jMDPLOgeBmVnGeWjI2oWWnpzPk+2ZfcpnBGZmGecgMGvC3XffTd++fenXrx9nn302r7/+OsOHD6dv374MHz6c1atXAzB27FguuugijjnmGA466CCeeOIJxo0bx6GHHsrYsWPrt9elSxeuuOIKBg4cyHHHHceCBQsYNmwYBx10ELNm5S6037hxI+eeey6VlZUMGDCAxx57DIA777yT0047jREjRlBRUcHll1/e6o+H7bwcBGYFLF26lJ/85CfMnTuXF198kRtvvJEJEybwzW9+k5deeokzzzyTiRMn1vd/9913mTt3LjfccAMnn3wy3/ve91i6dClLliypn5zuo48+YtiwYSxatIiuXbvywx/+kIcffpg//OEPTJ6cu+C+7qOmS5Ys4b777uOcc85h48aNACxevJgZM2awZMkSZsyYwZo1azBrCQ4CswLmzp3LqFGj6NatGwB77bUX8+fP5xvf+AYAZ599dv13EwCcfPLJSKKyspJ99tmHyspKOnTowGGHHVY/PUXnzp0ZMWIEAJWVlQwdOpROnTpRWVlZ32fevHmcffbZAPTu3ZsDDzyQ5cuXA7nvQNhjjz0oLS2lT58+vP76663xUFgGOAjMCoiIz0xH3Vj++l122QXIzVNUd7tuuba2FoBOnTrV3ye/X36frc1RlL/dkpKS+vuYfV4OArMChg8fzv3338/69esB2LBhA0cccQTTp08HcrOPNp6euiUcffTR3HvvvQAsX76c1atXc8ghh7T4fszy+eOj1i609sc9DzvsMK666iqGDh1KSUkJAwYM4KabbmLcuHFcf/31lJWVcccdd7T4fi+++GIuvPBCKisr6dixI3feeWeDMwGzNKi9fQ1AVVVVVFdXf65tFPsL49uStvp5+ldffZVDDz202GVkQlt9rNvC9xG0FS3xfQSSFkVEVaF1HhoyM8s4B4GZWcY5CMzMMs5BYGaWcQ4CM7OMSzUIJI2QtEzSCkmTmujzdUmvSFoq6bdp1mNmZp+V2nUEkkqAKcDXgBpgoaRZEfFKXp8K4ErgyIh4V9KX0qrH2reW/ihhS3wcz2xnkeYZwWBgRUSsjIiPgenAKY36nA9MiYh3ASLi7RTrMTOzAtIMgv2B/OkRa5K2fL2AXpKelvSspBGFNiTpAknVkqrXrVuXUrlmn1q1ahWHH354/fLPf/5zrr76aoYNG8YVV1zB4MGD6dWrF0899RQAn3zyCZdeeimVlZX07duXm2++GYBHH32UAQMGUFlZybhx49i0aRMAPXv25Ac/+AFf+cpXqKqq4vnnn+eEE07g4IMPZurUqQA8/vjjDB06lK9//ev06tWLSZMmce+99zJ48GAqKyv585//DLDV6bEnTpzIEUccwUEHHcTMmTNb7fGz9iXNICg0Y1fjy5g7AhXAMOAM4N8k7fmZO0VMi4iqiKgqKytr8ULNtkdtbS0LFizgl7/8Jddccw0A06ZN47XXXuOFF16on6Z648aNjB07tn7q6NraWm699db67fTo0YP58+fz1a9+lbFjxzJz5kyeffbZ+impgfopsJcsWcI999zD8uXLWbBgAeedd1592Gxteuy33nqLefPm8eCDDzJpUsG36cxSDYIaoEfecnfgzQJ9/m9EbI6I14Bl5ILBrM067bTTABg4cGD99NGPPPIIF154IR075t5222uvvVi2bBnl5eX06tULgHPOOYcnn3yyfjsjR44EclNSDxkyhK5du1JWVkZpaSnvvfceAIMGDWK//fZjl1124eCDD+b444+vv0/dvrc2Pfapp55Khw4d6NOnD3/5y19SekSsvUszCBYCFZLKJXUGxgCzGvX5D+AYAEndyA0VrUyxJrNm6dixI1u2bKlfrvtyGPh0Ouj8qaALTVu9rXm8mjN1deP2QlNXN1Zoeuzm1GPZlVoQREQtMAGYA7wK3B8RSyVdK2lk0m0OsF7SK8BjwGURsT6tmsyaa5999uHtt99m/fr1bNq0iQcffHCr/Y8//nimTp1a/+S8YcMGevfuzapVq1ixYgUA99xzD0OHDm3xWltjemzbuaU6DXVEzAZmN2qbnHc7gO8n/8ya1Nof9+zUqROTJ09myJAhlJeX07t37632P++881i+fDl9+/alU6dOnH/++UyYMIE77riD0aNHU1tby6BBg7jwwgtbvNbWmB7bdm6ehjrjPA21tdXH2tNQf8rTUJuZWaocBGZmGecgsDarvQ1btkd+jA0cBNZGlZaWsn79ej9RpSgiWL9+PaWlpcUuxYrMX15vbVL37t2pqanBU4qkq7S0lO7duxe7DCsyB4G1SZ06daK8vLzYZZhlgoeGzMwyzkFgZpZxDgIzs4xzEJiZZZyDwMws4xwEZmYZ5yAwM8s4B4GZWcY5CMzMMs5BYGaWcQ4CM7OMcxCYmWWcg8DMLONSDQJJIyQtk7RC0qQC68dKWidpcfLvvDTrMTOzz0ptGmpJJcAU4GtADbBQ0qyIeKVR1xkRMSGtOszMbOvSPCMYDKyIiJUR8TEwHTglxf2ZmdkOSDMI9gfW5C3XJG2N/S9JL0maKalHoQ1JukBStaRqf2OVmVnLSjMIVKCt8RfQ/hHoGRF9gUeAuwptKCKmRURVRFSVlZW1cJlmZtmWZhDUAPmv8LsDb+Z3iIj1EbEpWfw1MDDFeszMrIA0g2AhUCGpXFJnYAwwK7+DpP3yFkcCr6ZYj5mZFZDap4YiolbSBGAOUALcHhFLJV0LVEfELGCipJFALbABGJtWPWZmVlhqQQAQEbOB2Y3aJufdvhK4Ms0azMxs63xlsZlZxjkIzMwyzkFgZpZxqb5HYGbtz+WXX87atWvZd999ue6664pdjrUCB4GZNbB27VreeOONYpdhrchDQ2ZmGeczAisqD0M0NPCyu4tdAl3f+YASYPU7HxS1nj90LdquM8dBYEXlYQiz4vPQkJlZxvmMwMwa2NJ5twY/befnIDCzBj6qOL7YJVgrcxBk3OprK4u6/9oNewEdqd3wetFrOWDykqLu36xY/B6BmVnGOQjMzDLOQWBmlnF+j8CKqlvpFqA2+WlmxeAgsKK6tO97xS7BLPM8NGRmlnEOAjOzjHMQmJllXKpBIGmEpGWSVkiatJV+oySFpKo06zEzs89KLQgklQBTgBOBPsAZkvoU6NcVmAg8l1YtZmbWtDTPCAYDKyJiZUR8DEwHTinQ71+B64CNKdZiZmZNaFYQSPqdpH+StD3BsT+wJm+5JmnL3+4AoEdEPLiN/V8gqVpS9bp167ajBDMz25bmPrHfCnwD+G9J/0dS72bcRwXaon5lLlRuAP5lWxuKiGkRURURVWVlZc0s2czMmqNZQRARj0TEmcA/AKuAhyU9I+lcSZ2auFsN0CNvuTvwZt5yV+Bw4HFJq4B/BGb5DWMzs9bV7KEeSXsDY4HzgBeAG8kFw8NN3GUhUCGpXFJnYAwwq25lRLwfEd0iomdE9ASeBUZGRPWO/CJmZrZjmjXFhKTfA72Be4CTI+KtZNUMSQWfuCOiVtIEYA5QAtweEUslXQtUR8SsQvczM7PW1dy5hn4VEXMLrYiIJodyImI2MLtR2+Qm+g5rZi1mZtaCmhUEETFX0uHkrgcozWu/O63CzMysdTR3aOhHwDByQTCb3EVi8wAHgZlZO9fcN4tHAcOBtRFxLtAP2CW1qszMrNU0Nwj+HhFbgFpJuwNvAwelV5aZmbWW5r5ZXC1pT+DXwCLgQ2BBalWZmVmrae6bxRcnN6dK+hOwe0S8lF5ZZmbWWpo719CjdbcjYlVEvJTfZmZm7ddWzwgklQK7At0kfZFP5w/aHfgfKddmZmatYFtDQ98GvkvuSX9RXvsH5L5rwMzM2rltDQ09AxwBXBoRBwHXAC8DTwC/Tbk2MzNrBdsKgtuATRFxs6SjgZ8CdwHvA9PSLs7MzNK3raGhkojYkNw+HZgWEb8DfidpcbqlmZlZa9jWGUGJpLqwGA7kTzzX3GsQzMysDdvWk/l9wBOS3gH+DjwFIOnL5IaHzMysndtqEETET5LrBfYDHoqIuq+a7AB8J+3izMwsfdsc3omIZwu0LU+nHDMza23N/qpKMzPbOTkIzMwyzkFgZpZxDgIzs4xLNQgkjZC0TNIKSZMKrL9Q0hJJiyXNk9QnzXrMzOyzUgsCSSXkJqY7kdx3HZ9R4In+txFRGRH9geuAX6RVj5mZFZbmGcFgYEVErIyIj4HpwCn5HSLir3mLuwGBmZm1qjSnidgfWJO3XAMMadxJ0njg+0Bn4NgU6zEzswLSPCNQgbbPvOKPiCkRcTBwBfDDghuSLpBULal63bp1LVymmVm2pRkENUCPvOXuwJtb6T8dOLXQioiYFhFVEVFVVlbWgiWamVmaQbAQqJBULqkzMAaYld9BUkXe4j8B/51iPWZmVkBq7xFERK2kCcAcoAS4PSKWSroWqI6IWcAESccBm4F3gXPSqsfMzApL9TsFImI2MLtR2+S825ekuX8zM9s2X1lsZpZxDgIzs4xzEJiZZZyDwMws4xwEZmYZ5yAwM8s4B4GZWcY5CMzMMs5BYGaWcQ4CM7OMcxCYmWWcg8DMLOMcBGZmGecgMDPLOAeBmVnGOQjMzDLOQWBmlnEOAjOzjHMQmJllnIPAzCzjUg0CSSMkLZO0QtKkAuu/L+kVSS9JelTSgWnWY2Zmn5VaEEgqAaYAJwJ9gDMk9WnU7QWgKiL6AjOB69Kqx8zMCkvzjGAwsCIiVkbEx8B04JT8DhHxWET8LVl8FuieYj1mZlZAmkGwP7Amb7kmaWvKt4D/l2I9ZmZWQMcUt60CbVGwo3QWUAUMbWL9BcAFAAcccEBL1WdmZqR7RlAD9Mhb7g682biTpOOAq4CREbGp0IYiYlpEVEVEVVlZWSrFmpllVZpBsBCokFQuqTMwBpiV30HSAOA2ciHwdoq1mJlZE1ILgoioBSYAc4BXgfsjYqmkayWNTLpdD3QBHpC0WNKsJjZnZmYpSfM9AiJiNjC7UdvkvNvHpbl/MzPbNl9ZbGaWcQ4CM7OMcxCYmWWcg8DMLOMcBGZmGecgMDPLOAeBmVnGOQjMzDLOQWBmlnEOAjOzjHMQmJllnIPAzCzjHARmZhnnIDAzyzgHgZlZxjkIzMwyzkFgZpZxDgIzs4xzEJiZZZyDwMws4xwEZmYZl2oQSBohaZmkFZImFVh/tKTnJdVKGpVmLWZmVlhqQSCpBJgCnAj0Ac6Q1KdRt9XAWOC3adVhZmZb1zHFbQ8GVkTESgBJ04FTgFfqOkTEqmTdlhTrMDOzrUhzaGh/YE3eck3Stt0kXSCpWlL1unXrWqQ4MzPLSTMIVKAtdmRDETEtIqoioqqsrOxzlmVmZvnSDIIaoEfecnfgzRT3Z2ZmOyDNIFgIVEgql9QZGAPMSnF/Zma2A1ILgoioBSYAc4BXgfsjYqmkayWNBJA0SFINMBq4TdLStOoxM7PC0vzUEBExG5jdqG1y3u2F5IaMzMysSHxlsZlZxjkIzMwyzkFgZpZxDgIzs4xzEJiZZZyDwMws4xwEZmYZ5yAwM8s4B4GZWcY5CMzMMs5BYGaWcQ4CM7OMcxCYmWWcg8DMLOMcBGZmGecgMDPLOAeBmVnGOQjMzDLOQWBmlnEOAjOzjEs1CCSNkLRM0gpJkwqs30XSjGT9c5J6plmPmZl9VmpBIKkEmAKcCPQBzpDUp1G3bwHvRsSXgRuAn6VVj5mZFZbmGcFgYEVErIyIj4HpwCmN+pwC3JXcngkMl6QUazIzs0Y6prjt/YE1ecs1wJCm+kREraT3gb2Bd/I7SboAuCBZ/FDSslQqzqADoRuNHu/M+pFfg7QlPjbztMyxeWBTK9IMgkKVxw70ISKmAdNaoihrSFJ1RFQVuw6zxnxstp40h4ZqgB55y92BN5vqI6kjsAewIcWazMyskTSDYCFQIalcUmdgDDCrUZ9ZwDnJ7VHA3Ij4zBmBmZmlJ7WhoWTMfwIwBygBbo+IpZKuBaojYhbwG+AeSSvInQmMSasea5KH3Kyt8rHZSuQX4GZm2eYri83MMs5BYGaWcQ4C2yZJqyR1247+YyX9Ks2azLZGUk9JL2/nfe6UNCqtmtoyB0E7o5w0pwZJ89oSy6DWOKaSKW1sBzkI2oHk1c2rkm4BngfOljRf0vOSHpDURdJgSb9P+p8i6e+SOksqlbQyaT9f0kJJL0r6naRdk/Y7Jf1C0mPAzyTtLekhSS9Iuo28C/8knSVpgaTFkm6r+wOUdK6k5ZKeAI5s5YfIUtb4FbakSyVdLelxST9Ljonlkr6arB+bHJt/BB5K2i5Ljr+XJF2TtF0uaWJy+wZJc5PbwyX9e3L7VknVkpbW3S9pXyVpsqR5wGhJA5Njez4wPq9fiaTr8/b97aRdkn4l6RVJ/wl8Kd1Hse1yELQfhwB3A18jN1nfcRHxD0A18H1yATEg6ftV4GVgELlpPZ5L2n8fEYMioh/warKdOr2Sbf4L8CNgXkQMIHetxwEAkg4FTgeOjIj+wCfAmZL2A64hFwBfIzfJoGVHx4gYDHyX3LFT5yvAORFxrKTjgQpyc5D1BwZKOhp4ktzxClAFdJHUCTgKeCppvyq5wrgvMFRS37x9bIyIoyJiOnAHMDEivtKovm8B70fEIHJ/E+dLKgf+mdzfVSVwPnDE534k2ikPA7Qfr0fEs5JOIvdE+3QyP19nYH5y3caK5Ml6MPAL4Ghy13DU/UEdLunHwJ5AF3LXeNR5ICI+SW4fDZwGEBH/KendpH04MBBYmOz7C8Db5MLm8YhYByBpBrlgsWz4ffJzEdAzr/3hiKibKeD45N8LyXIXcsFwN7lQ6ApsIveCpopcOExM+n49mW+sI7AfueP/pWTdDABJewB7RsQTSfs95GY+rtt337zx/z2SfR8N3Jcc92/WnY1kkYOg/fgo+Slyf2BnFOjzFLmDfzPwCHAnuSC4NFl/J3BqRLwoaSwwrMD26xS6wETAXRFxZYNG6dQm+tvOo5aGIwilebc3JT8/oeFzSv4xJeCnEXFb4w1LWgWcCzxD7gn+GOBg4NXklfulwKCIeFfSnY32nf930dQxKOA7ETGnQaP0P7dyn0zx0FD78yxwpKQvA0jaVVLdq+8nyZ2ez09ene8N9AaWJuu7Am8lp95nbmUfT9atl3Qi8MWk/VFglKQvJev2knQguaGnYcl7C52A0S3zq1ob8hfgS8n/8S7ASdt5/znAOEldACTtX3cckTveLk1+PgVcCCxOppvZndyT/fuS9uHTV/kNRMR7SZ+jkqb843sOcFFybCKpl6Tdkv2NSd5D2I9cAGWSzwjamYhYl7yavy/5gwT4IbCc3BPyPuQOcMi9uno7b/6m/530eR1YQi4YCrkm2f7zwBPA6mTfr0j6IfCQcp9c2gyMT4asrgbmA2+RO733pzh2IhGxWbnpYZ4DXgP+azvv/1AybDk/GVb8EDiL3NDiU8BV5F7AfCRpY9JGcvb6ArkXMyuBp7eym3OB2yX9jYbDnv9GbsjqeeV2vg44FfgDcCy5v4Xl5I71TPIUE2ZmGeehITOzjHMQmJllnIPAzCzjHARmZhnnIDAzyzgHgZlZxjkIzIogmejvtWTyvhclDS92TZZdDgKz7aCWne74smTyvu8CU1twu2bbxUFglkimWv4vSXcl0xXPTKbwaDzd8cGS/iRpkaSnJPWWtEfSr0OyrV0lramb1mAb5gP7p/rLmW2Fg8CsoUOAaRHRF/grcHHSnj/d8TRyk5gNJDdHzi0R8T7wIjA06X8yMCciNjdjnyOA/2jJX8Jse3iuIbOG1kRE3Xw2/86nUyHXTXfchdy89Q8kc+YA7JLX53TgMWAMcMs29nW9pOvIfSHKP7ZI9WY7wEFg1lDjybfqluumO+4AvJeM7Tc2C/ippL3IfW/Dtua3v4zcXP4TgbuS+5i1Og8NmTV0gKS6b7g6A5iXvzIi/gq8Jmk01H/dYb9k3YfAAuBG4MG8L/ppUkRsSfp3kHRCy/0aZs3nIDBr6FXgHEkvAXsBtxbocybwLUkvkpse+ZS8dTPITa88o7k7TKYJ/zFw+Y4WbfZ5eBpqs4SknuReyR9e5FLMWpXPCMzMMs5nBGYpkjQFOLJR840RcUcx6jErxEFgZpZxHhoyM8s4B4GZWcY5CMzMMs5BYGaWcf8fEIxYxd7qQeUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pandas import DataFrame, concat\n",
    "np.random.seed(47404)\n",
    "\n",
    "data = []\n",
    "for _ in tqdm(range(200)):\n",
    "    \n",
    "    ## Simulate outcomes.\n",
    "    R = np.random.binomial(1, [[0.5,0.5],[0.5,0.5]], (200,2,2))\n",
    "    \n",
    "    ## Initialize agent.\n",
    "    agent = ModelBased(beta_1 = 8, beta_2 = 8, eta_2=0.4)\n",
    "\n",
    "    ## Train agent.\n",
    "    Y, t, r = agent.train(R)\n",
    "    \n",
    "    ## Define variables.\n",
    "    prev_R = np.roll(r, 1)[1:]\n",
    "    prev_T = np.roll(t, 1)[1:]\n",
    "    stay = Y[:-1,0] == Y[1:,0]\n",
    "\n",
    "    ## Blah.\n",
    "    df = DataFrame(np.column_stack([prev_R, prev_T, stay]), columns=['prev_R', 'prev_T', 'Stay'])\n",
    "    data.append(df)\n",
    "    \n",
    "## Concatenate DataFrames.\n",
    "data = concat(data)\n",
    "data.prev_R = data.prev_R.replace({1:'rewarded',0:'unrewarded'})\n",
    "data.prev_T = data.prev_T.replace({1:'common',0:'uncommon'})\n",
    "\n",
    "ax = sns.barplot('prev_R', 'Stay', 'prev_T', data=data, order=['rewarded','unrewarded'], \n",
    "                 hue_order=['common','uncommon'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
