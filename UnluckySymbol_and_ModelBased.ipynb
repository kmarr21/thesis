{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pystan\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import njit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rewards import Rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rs = Rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "805"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from Sam Zorowitz code — add citation here!\n",
    "\n",
    "@njit\n",
    "def inv_logit(arr):\n",
    "    \"\"\"Fast inverse logistic function.\"\"\"\n",
    "    return 1. / (1. + np.exp(-arr))\n",
    "\n",
    "@njit\n",
    "def softmax(arr):\n",
    "    \"\"\"Scale-robust softmax function\"\"\"\n",
    "    arr = np.exp(arr - np.max(arr))\n",
    "    return arr / arr.sum()\n",
    "\n",
    "@njit\n",
    "def phi_approx(arr):\n",
    "    '''Elementwise fast approximation of the cumulative unit normal.'''\n",
    "    return inv_logit(0.07056 * arr ** 3 + 1.5976 * arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "SA = 0\n",
    "SB = 1\n",
    "SC = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnluckySymbol(object):\n",
    "    def __init__(self, trials, Rs, a, b, eta):\n",
    "        \n",
    "        self.n_trials = trials\n",
    "        \n",
    "        self.R = Rs\n",
    "        self.state = SA\n",
    "        \n",
    "        # define parameters\n",
    "        self.alpha = a\n",
    "        self.beta = b\n",
    "        self.eta = eta\n",
    "        \n",
    "        # define values\n",
    "        self.MB = np.zeros((2, 2))\n",
    "        \n",
    "        self.rewards = np.zeros(trials)\n",
    "        self.choices = np.zeros((trials, 2))\n",
    "        self.choice1_outcomes = np.zeros(trials)\n",
    "        self.switch = np.zeros(trials)\n",
    "        self.common = np.zeros(trials)\n",
    "        \n",
    "        self.transitions = np.array([\n",
    "            [0.7, 0.3],\n",
    "            [0.3, 0.7]\n",
    "        ])\n",
    "        \n",
    "        self.transition_count = np.zeros((2,2,2))\n",
    "        self.final_state = np.zeros(trials) # 1 = SB, 2 = SC\n",
    "        \n",
    "    def possible_switch(self, choice):\n",
    "        if random.random() < 0.7:\n",
    "            return choice\n",
    "        return 1 - choice\n",
    "    \n",
    "    def update_stay_prob(self, action, t):\n",
    "        self.transition_count[\n",
    "            int(not self.rewards[t-1]),\n",
    "            int(not self.common[t-1]),\n",
    "            int(not (self.choice1_outcomes[t-1] == action))\n",
    "        ] += 1\n",
    "        \n",
    "    def compute_stay_prob(self, transition_count):\n",
    "        # stay_prob[r,c,a] = P[r,c,a] / (P[r,c,a] + P[r,c,~a]) \n",
    "        action_count = transition_count.sum(axis=-1)\n",
    "        return transition_count / action_count[:, :, np.newaxis]\n",
    "\n",
    "    def train(self, R):\n",
    "        \n",
    "        for t in range(self.n_trials):\n",
    "            \n",
    "            self.state = SA\n",
    "            \n",
    "            ## Action selection.\n",
    "            d1 = 0.7*max(self.MB[1]) + 0.3*max(self.MB[0]) - self.eta*(0.3*max(self.MB[1]) + 0.7*max(self.MB[0]))\n",
    "            \n",
    "            # choice probabilities and making choice\n",
    "            theta1 = inv_logit( self.beta * d1 )\n",
    "            choice1 = np.random.binomial(1, theta1)\n",
    "            self.choices[t,0] = choice1\n",
    "            \n",
    "            # observe outcome and possible switch\n",
    "            outcome1 = self.possible_switch(choice1)\n",
    "            self.choice1_outcomes[t] = outcome1\n",
    "            \n",
    "            # update values for stay_probs\n",
    "            if t > 0:    \n",
    "                self.update_stay_prob(outcome1, t)\n",
    "            \n",
    "            reward_probs = None\n",
    "            # update state\n",
    "            if self.choice1_outcomes[t] == 0: # went LEFT\n",
    "                self.state = SB\n",
    "                self.final_state[t] = 1\n",
    "                reward_probs = self.R[t][0:2]\n",
    "            else: # went RIGHT\n",
    "                self.state = SC\n",
    "                self.final_state[t] = 2\n",
    "                reward_probs = self.R[t][2:4]\n",
    "            \n",
    "            # count possible switch\n",
    "            if (self.choices[t,0] == 1 & self.state == SB) | (self.choices[t,0] == 0 & self.state == SC):\n",
    "                self.switch[t] = 1\n",
    "            else:\n",
    "                self.common[t] = 1\n",
    "            \n",
    "            # possible value reduction\n",
    "            value_reduc = eta if (choice1 == 0) else 1\n",
    "            \n",
    "            # make second-level choice\n",
    "            d2 = value_reduc*self.beta*(self.MB[outcome1,1] - self.MB[outcome1,0])\n",
    "\n",
    "            theta2 = inv_logit( d2 )\n",
    "            choice2 = np.random.binomial(1, theta2)\n",
    "            self.choices[t,1] = choice2\n",
    "            \n",
    "            # get what the reward is\n",
    "            final_prob = reward_probs[choice2]\n",
    "            reward = np.random.binomial(1, final_prob)\n",
    "            self.rewards[t] = reward\n",
    "            \n",
    "            # update values\n",
    "            self.MB[outcome1, choice2] = (1 - self.alpha)*self.MB[outcome1, choice2] + self.alpha*self.rewards[t]\n",
    "\n",
    "            \n",
    "    def plot(self, transition_count=None, title=\"Unlucky Symbol: Two-Step Task\", y_lim=0.5):\n",
    "        _,ax = plt.subplots(1,1,figsize=[10,6])\n",
    "\n",
    "        ax.set_ylim([y_lim, 1.0])\n",
    "        ax.set_ylabel('Stay Probability')\n",
    "        ax.set_title(title)\n",
    "\n",
    "        if transition_count is None:\n",
    "            transition_count = self.transition_count\n",
    "        \n",
    "        stay_probs = self.compute_stay_prob(transition_count)\n",
    "        \n",
    "        common = [stay_probs[0,0,0], stay_probs[1,0,0]]\n",
    "        uncommon = [stay_probs[0,1,0], stay_probs[1,1,0]]\n",
    "        \n",
    "        ax.set_xticks([1.5,3.5])\n",
    "        ax.set_xticklabels(['Rewarded', 'Unrewarded'])\n",
    "        ax.set_ylim(0,1)\n",
    "        \n",
    "        c = plt.bar([1,3], common, color='b', width=0.5)\n",
    "        uc = plt.bar([2,4], uncommon, color='r', width=0.5)\n",
    "        ax.legend( (c[0], uc[0]), ('Common', 'Uncommon') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_agents = 1\n",
    "trials = 400\n",
    "alpha = 0.5\n",
    "beta = 5.00\n",
    "eta  = 0.5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agents = UnluckySymbol(trials, Rs, alpha, beta, eta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(47404)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = agents.train(Rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agents.final_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rew = agents.rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rares = agents.switch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "commons = agents.common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# looking for HIGHER STAY PROBABILITY:\n",
    "    # if common and was rewarded ()\n",
    "    # or uncommon and wasn't rewarded (switch, and no reward)\n",
    "\n",
    "com_rew = []\n",
    "com_unrew = []\n",
    "\n",
    "rare_unrew = []\n",
    "rare_rew = []\n",
    "    \n",
    "for i in range(trials):\n",
    "    if (commons[i] == 1):\n",
    "        com_rew.append(i) if (rew[i] == 1) else com_unrew.append(i)\n",
    "\n",
    "    if (rares[i] == 1):\n",
    "        rare_unrew.append(i) if (rew[i] == 0) else rare_rew.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(com_rew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(rare_unrew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(rare_rew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(com_unrew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agents.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [EDIT] Sam Notes\n",
    "\n",
    "In this cell, I'll review the equations for the model-based agent, originally defined in the [supplement of Daw et al (2011)](https://ars.els-cdn.com/content/image/1-s2.0-S0896627311001255-mmc1.pdf). \n",
    "\n",
    "#### Stage 2 Choice\n",
    "\n",
    "In stage 2, the agent makes a choice between two actions, $Q(s_i, a_1)$ and $Q(s_i,a_2$), conditioned on the current state. As discussed in [Daw (2011)](https://pdfs.semanticscholar.org/43c3/d7653710bbb477df108fc2ed2729429d053c.pdf), in the case of two options, the softmax reduces to the [inverse logit function](https://en.wikipedia.org/wiki/Logistic_function). Thus, the probability of the agent taking action 1 is:\n",
    "\n",
    "$$ p( a_1 \\mid s_i, \\beta_2 ) = \\text{logit}^{-1} \\left( \\beta_2 \\cdot [Q(s_i, a_1) - Q(s_i, a_2)] \\right) = \\frac{1}{1 + \\exp \\left(-\\beta_2 \\cdot [Q(s_i, a_1) - Q(s_i, a_2)] \\right)} $$\n",
    "\n",
    "Note that the action probability is a function of a choice sensitivity (inverse temperature) parameter, $\\beta_2$. The subscript indicates that this parameter is specific to the second stage. As you will see below, we introduce a separate choice sensitivity parameter for first stage choice (even though we typically set these to the same value).\n",
    "\n",
    "#### Stage 2 Learning\n",
    "\n",
    "In stage 2, following a choice, the agent updates its expectations of the value of the chosen action, $Q(s_{i,t+1} a_{i,t+1})$, based on the observed reward, $r_t$. This update folows temporal difference learning:\n",
    "\n",
    "$$ Q(s_{i,t+1} a_{i,t+1}) = Q(s_{i,t}, a_{i,t}) + \\eta_2 \\delta_t $$\n",
    "\n",
    "where $\\delta_t$ is the reward prediction error on trial $t$, defined as:\n",
    "\n",
    "$$ \\delta_t = r_t - Q(s_{i,t}, a_{i,t}) $$\n",
    "\n",
    "Two notes here:\n",
    "\n",
    "1. We introduce the trial $t$ notation here to denote that learning updates affect behavior on the next trial.\n",
    "2. We introduce the stage notation here for learning rate to indicate that this parameter is specific to stage 2.\n",
    "\n",
    "#### Stage 1 Choice\n",
    "\n",
    "Now here's the complicated part. We make two assumptions about the model-based agent:\n",
    "\n",
    "1. The agent recomputes the value of each stage 1 action based on its current estimates of the value of the second stage choices at the start of each trial.\n",
    "2. The agent performs this computation assuming an *off-policy* strategy (i.e. assuming it will take the best action at any successor state).\n",
    "\n",
    "Following Bellman's equation, the model-based agent computes the value of each first stage action taking into consideration the state-transition probaiblities, $T(s' \\mid s_1, a_i)$, and value of the best action in each successor state. \n",
    "\n",
    "For notational convenience, let's define the transition probabilities as:\n",
    "- $ p( s_2 \\mid s_1, a_1) = 0.7 $, i.e. 70% probability of ending up in State 2 given Action 1 in State 1\n",
    "- $ p( s_3 \\mid s_1, a_1) = 0.3 $, i.e. 30% probability of ending up in State 3 given Action 1 in State 1\n",
    "- $ p( s_2 \\mid s_1, a_2) = 0.3 $, i.e. 30% probability of ending up in State 2 given Action 2 in State 1\n",
    "- $ p( s_3 \\mid s_1, a_2) = 0.7 $, i.e. 70% probability of ending up in State 3 given Action 2 in State 1\n",
    "\n",
    "Then we can define the value of action 1 in stage 1 as:\n",
    "\n",
    "$$ Q(s_1, a_1) = p( s_2 \\mid s_1, a_1) \\cdot \\max Q(s_2, a) + p( s_3 \\mid s_1, a_1) \\cdot \\max Q(s_3, a) $$\n",
    "$$ = 0.7 \\cdot \\max Q(s_2, a) + 0.3 \\cdot \\max Q(s_3, a) $$\n",
    "\n",
    "and the value of action 2 in stage 1 as:\n",
    "\n",
    "$$ Q(s_1, a_2) = p( s_2 \\mid s_1, a_2) \\cdot \\max Q(s_2, a) + p( s_3 \\mid s_1, a_2) \\cdot \\max Q(s_3, a) $$\n",
    "$$ = 0.3 \\cdot \\max Q(s_2, a) + 0.7 \\cdot \\max Q(s_3, a) $$\n",
    "\n",
    "And finally, we use the inverse logit function to assign probabilities of taking either action 1 vs. action 2 in stage 1:\n",
    "\n",
    "$$ p( a_1 \\mid s_1, \\beta_1 ) = \\text{logit}^{-1} \\left( \\beta_1 \\cdot [Q(s_1, a_1) - Q(s_1, a_2)] \\right) = \\frac{1}{1 + \\exp \\left(-\\beta_1 \\cdot [Q(s_1, a_1) - Q(s_1, a_2)] \\right)} $$\n",
    "\n",
    "\n",
    "Note that the action probability is a function of a separate choice sensitivity (inverse temperature) parameter, $\\beta_1$. The subscript indicates that this parameter is specific to the first stage. As noted above, we typically set the value of choice sensitivity for both stages, $\\beta_1$ and $\\beta_2$, to be the same but they don't have to be!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model-Based Strategy\n",
    "\n",
    "class model_based(object):\n",
    "    def __init__(self, trials, Rs, a, b1, b2=None):\n",
    "        \n",
    "        self.n_trials = trials\n",
    " \n",
    "        self.R = Rs\n",
    "        self.state = SA\n",
    "        \n",
    "        # define parameters\n",
    "        self.alpha = a\n",
    "        self.beta1 = b1\n",
    "        \n",
    "        if b2 == None:\n",
    "            self.beta2 = b1\n",
    "        else:\n",
    "            self.beta2 = b2\n",
    "        \n",
    "        # define values\n",
    "        self.MB = np.zeros((2, 2))\n",
    "        \n",
    "        self.rewards = np.zeros(trials)\n",
    "        self.choices = np.zeros((trials, 2))\n",
    "        self.choice1_outcomes = np.zeros(trials)\n",
    "        self.switch = np.zeros(trials)\n",
    "        self.common = np.zeros(trials)\n",
    "        \n",
    "        self.transitions = np.array([\n",
    "            [0.7, 0.3],\n",
    "            [0.3, 0.7]\n",
    "        ])\n",
    "        \n",
    "        self.transition_count = np.zeros((2,2,2))\n",
    "        self.final_state = np.zeros(trials) # 1 = SB, 2 = SC\n",
    "        \n",
    "    def possible_switch(self, choice):\n",
    "        if random.random() < 0.7:\n",
    "            return choice\n",
    "        return 1 - choice\n",
    "    \n",
    "    def update_stay_prob(self, action, t):\n",
    "        self.transition_count[\n",
    "            int(not self.rewards[t-1]),\n",
    "            int(not self.common[t-1]),\n",
    "            int(not (self.choice1_outcomes[t-1] == action))\n",
    "        ] += 1\n",
    "        \n",
    "    def compute_stay_prob(self, transition_count):\n",
    "        # stay_prob[r,c,a] = P[r,c,a] / (P[r,c,a] + P[r,c,~a]) \n",
    "        action_count = transition_count.sum(axis=-1)\n",
    "        return transition_count / action_count[:, :, np.newaxis]\n",
    "\n",
    "    def train(self, R):\n",
    "        \n",
    "        for t in range(self.n_trials):\n",
    "            \n",
    "            self.state = SA\n",
    "            \n",
    "            ## Action selection.\n",
    "            v1 = 0.7*max(self.MB[0]) + 0.3*max(self.MB[1])\n",
    "            v2 = 0.3*max(self.MB[0]) + 0.7*max(self.MB[1])\n",
    "\n",
    "            # choice probabilities and making choice\n",
    "            theta1 = inv_logit( self.beta1 * (v1 - v2) )\n",
    "            choice1 = np.random.binomial(1, theta1)\n",
    "            self.choices[t,0] = choice1\n",
    "            \n",
    "            # observe outcome and possible switch\n",
    "            outcome1 = self.possible_switch(choice1)\n",
    "            self.choice1_outcomes[t] = outcome1\n",
    "            \n",
    "            # update values for stay_probs\n",
    "            if t > 0:    \n",
    "                self.update_stay_prob(outcome1, t)\n",
    "            \n",
    "            reward_probs = None\n",
    "            # update state\n",
    "            if self.choice1_outcomes[t] == 0: # went LEFT\n",
    "                self.state = SB\n",
    "                self.final_state[t] = 1\n",
    "                reward_probs = self.R[t][0:2]\n",
    "            else: # went RIGHT\n",
    "                self.state = SC\n",
    "                self.final_state[t] = 2\n",
    "                reward_probs = self.R[t][2:4]\n",
    "            \n",
    "            # count possible switch\n",
    "            if (self.choices[t,0] == 1 & self.state == SB) | (self.choices[t,0] == 0 & self.state == SC):\n",
    "                self.switch[t] = 1\n",
    "            else:\n",
    "                self.common[t] = 1\n",
    "            \n",
    "            # make second-level choice\n",
    "            d2 = self.MB[outcome1,0] - self.MB[outcome1,1]\n",
    "\n",
    "            theta2 = inv_logit( self.beta2 * d2 )\n",
    "            choice2 = np.random.binomial(1, theta2)\n",
    "            self.choices[t,1] = choice2\n",
    "            \n",
    "            # get what the reward is\n",
    "            final_prob = reward_probs[choice2]\n",
    "            reward = np.random.binomial(1, final_prob)\n",
    "            self.rewards[t] = reward\n",
    "            \n",
    "            # update values\n",
    "            # update level 2 MB value\n",
    "            self.MB[outcome1, choice2] += self.alpha*(self.rewards[t] - self.MB[outcome1, choice2])\n",
    "            \n",
    "        return self\n",
    "            \n",
    "    def plot(self, transition_count=None, title=\"Model-Based Two-Step Task\", y_lim=0.5):\n",
    "        _,ax = plt.subplots(1,1,figsize=[10,6])\n",
    "\n",
    "        ax.set_ylim([y_lim, 1.0])\n",
    "        ax.set_ylabel('Stay Probability')\n",
    "        ax.set_title(title)\n",
    "\n",
    "        if transition_count is None:\n",
    "            transition_count = self.transition_count\n",
    "        \n",
    "        stay_probs = self.compute_stay_prob(transition_count)\n",
    "        \n",
    "        common = [stay_probs[0,0,0], stay_probs[1,0,0]]\n",
    "        uncommon = [stay_probs[0,1,0], stay_probs[1,1,0]]\n",
    "        \n",
    "        ax.set_xticks([1.5,3.5])\n",
    "        ax.set_xticklabels(['Rewarded', 'Unrewarded'])\n",
    "        ax.set_ylim(0,1)\n",
    "        \n",
    "        c = plt.bar([1,3], common, color='b', width=0.5)\n",
    "        uc = plt.bar([2,4], uncommon, color='r', width=0.5)\n",
    "        ax.legend( (c[0], uc[0]), ('Common', 'Uncommon') )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.random.seed(11408)\n",
    "\n",
    "## Define parameters\n",
    "n_agents = 1\n",
    "trials = 200\n",
    "alpha = 0.2\n",
    "beta = 10.00\n",
    "\n",
    "## Initialize agent.\n",
    "agents_MB = model_based(trials, Rs, alpha, beta)\n",
    "\n",
    "## Train agent.\n",
    "agents_MB.train(Rs[:200])\n",
    "\n",
    "agents_MB.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [EDIT] Sam Testing\n",
    "\n",
    "In this cell, I train 200 instances of `model_based` on a purely random game (i.e. all stage 2 bandits reward 50% of the time). I then try to recreate the figure from Daw et al 2011."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 103.82it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pandas import DataFrame, concat\n",
    "from tqdm import tqdm\n",
    "np.random.seed(11408)\n",
    "\n",
    "## Define parameters\n",
    "n_agents = 1\n",
    "trials = 200\n",
    "alpha = 0.4\n",
    "beta = 8\n",
    "\n",
    "## Reward probabilities all 50/50.\n",
    "Rs = 0.5 * np.ones((200,4))\n",
    "\n",
    "data = []\n",
    "for _ in tqdm(range(200)):\n",
    "    \n",
    "    ## Initialize agent.\n",
    "    agents_MB = model_based(trials, Rs[:trials], alpha, beta)\n",
    "\n",
    "    ## Train agent.\n",
    "    agents_MB.train(Rs[:trials])\n",
    "    \n",
    "    Y = agents_MB.choices[:,0].copy()\n",
    "    R = agents_MB.rewards.copy()\n",
    "    T = (Y == agents_MB.choice1_outcomes).astype(int)\n",
    "\n",
    "    prev_R = np.roll(R, 1)[1:]\n",
    "    prev_T = np.roll(T, 1)[1:]\n",
    "    stay = Y[:-1] == Y[1:]\n",
    "\n",
    "    df = DataFrame(np.column_stack([prev_R, prev_T, stay]), columns=['prev_R', 'prev_T', 'Stay'])\n",
    "    data.append(df)\n",
    "    \n",
    "## Concatenate DataFrames.\n",
    "data = concat(data)\n",
    "data.prev_R = data.prev_R.replace({1:'rewarded',0:'unrewarded'})\n",
    "data.prev_T = data.prev_T.replace({1:'common',0:'uncommon'})\n",
    "\n",
    "ax = sns.barplot('prev_R', 'Stay', 'prev_T', data=data, order=['rewarded','unrewarded'], \n",
    "                 hue_order=['common','uncommon'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [EDIT] Sam Testing\n",
    "\n",
    "In this cell, I write a second version of `ModelBased` as a comparison with the above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def inv_logit(arr):\n",
    "    \"\"\"Fast inverse logistic function.\"\"\"\n",
    "    return 1. / (1. + np.exp(-arr))\n",
    "\n",
    "\n",
    "class ModelBased(object):\n",
    "    \n",
    "    def __init__(self, beta_1, beta_2, eta_2):\n",
    "        \n",
    "        ## Define parameters.\n",
    "        self.beta_1 = beta_1\n",
    "        self.beta_2 = beta_2\n",
    "        self.eta_2 = eta_2\n",
    "        \n",
    "        ## Initialize Q-values.\n",
    "        self.Q = None\n",
    "        \n",
    "    def train(self, R, T=[[0.7,0.3],[0.3,0.7]], reset=False):\n",
    "        \n",
    "        ## Error-catching: rewards.\n",
    "        R = np.array(R)\n",
    "        \n",
    "        ## Error-catching: transition probabilities.\n",
    "        T = np.array(T)\n",
    "        \n",
    "        ## Initialize Q-values.\n",
    "        if self.Q is None or reset:\n",
    "            self.Q = 0.5 * np.ones((3,2))\n",
    "            \n",
    "        ## Preallocate space.\n",
    "        n_trials = R.shape[0]\n",
    "        Y = np.zeros((n_trials, 2), dtype=int)\n",
    "        t = np.zeros(n_trials, dtype=int)\n",
    "        r = np.zeros(n_trials)\n",
    "            \n",
    "        for i in range(n_trials):\n",
    "            \n",
    "            ## Stage 1: Re-compute Q-values.\n",
    "            self.Q[0] = T @ self.Q[1:].max(axis=1)\n",
    "            \n",
    "            ## Stage 1: Compute choice likelihood.\n",
    "            theta = inv_logit( self.beta_1 * np.diff(self.Q[0]) )\n",
    "            \n",
    "            ## Stage 1: Simulate choice.\n",
    "            Y[i,0] = np.random.binomial(1,theta)\n",
    "            \n",
    "            ## Simulate transition.\n",
    "            t[i] = np.random.binomial(1, 0.7)\n",
    "            S = np.where(t[i], Y[i,0], 1-Y[i,0]) + 1\n",
    "                        \n",
    "            ## Stage 2: Compute choice likelihood.\n",
    "            theta = inv_logit( self.beta_2 * np.diff(self.Q[S]) )\n",
    "            \n",
    "            ## Stage 2: Simulate choice.\n",
    "            Y[i,1] = np.random.binomial(1,theta)\n",
    "            \n",
    "            ## Stage 2: Observe outcome.\n",
    "            r[i] = R[i,S-1,Y[i,1]]\n",
    "            \n",
    "            ## Stage 2: Update Q-values.\n",
    "            self.Q[S,Y[i,1]] += self.eta_2 * ( r[i] - self.Q[S,Y[i,1]] )\n",
    "            \n",
    "        return Y, t, r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [EDIT] Sam Testing\n",
    "\n",
    "In this cell, I train 200 instances of `ModelBased` on a purely random game (i.e. all stage 2 bandits reward 50% of the time). I then try to recreate the figure from Daw et al 2011."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:07<00:00, 27.84it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pandas import DataFrame, concat\n",
    "np.random.seed(47404)\n",
    "\n",
    "data = []\n",
    "for _ in tqdm(range(200)):\n",
    "    \n",
    "    ## Simulate outcomes.\n",
    "    R = np.random.binomial(1, [[0.5,0.5],[0.5,0.5]], (200,2,2))\n",
    "    \n",
    "    ## Initialize agent.\n",
    "    agent = ModelBased(beta_1 = 8, beta_2 = 8, eta_2=0.4)\n",
    "\n",
    "    ## Train agent.\n",
    "    Y, t, r = agent.train(R)\n",
    "    \n",
    "    ## Define variables.\n",
    "    prev_R = np.roll(r, 1)[1:]\n",
    "    prev_T = np.roll(t, 1)[1:]\n",
    "    stay = Y[:-1,0] == Y[1:,0]\n",
    "\n",
    "    ## Blah.\n",
    "    df = DataFrame(np.column_stack([prev_R, prev_T, stay]), columns=['prev_R', 'prev_T', 'Stay'])\n",
    "    data.append(df)\n",
    "    \n",
    "## Concatenate DataFrames.\n",
    "data = concat(data)\n",
    "data.prev_R = data.prev_R.replace({1:'rewarded',0:'unrewarded'})\n",
    "data.prev_T = data.prev_T.replace({1:'common',0:'uncommon'})\n",
    "\n",
    "ax = sns.barplot('prev_R', 'Stay', 'prev_T', data=data, order=['rewarded','unrewarded'], \n",
    "                 hue_order=['common','uncommon'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
